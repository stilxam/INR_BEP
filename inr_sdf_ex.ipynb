{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of training an INR locally\n",
    "This notebook provides an example of how to create an INR and train it locally using the tools in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:08.046552438Z",
     "start_time": "2025-01-30T11:32:04.645266838Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmaxwell_litsios\u001B[0m (\u001B[33mbep-circle\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import traceback\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "import wandb\n",
    "\n",
    "from common_dl_utils.config_creation import Config\n",
    "import common_jax_utils as cju\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "key = jax.random.PRNGKey(12398)\n",
    "key_gen = cju.key_generator(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:08.285684425Z",
     "start_time": "2025-01-30T11:32:07.794614779Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train a single INR on `example_data/parrot.png`. We'll use the `CombinedINR` clas from `model_components.inr_modules` together with the `SirenLayer` and `GaussianINRLayer` from `model_components.inr_layers` for the model, and we'll train it using the tools from `inr_utils`.\n",
    "\n",
    "To do all of this, basically we only need to create a config. We'll use the `common_dl_utils.config_creation.Config` class for this, but this is basically just a dictionary that allows for attribute access-like acces of its elements (so we can do `config.model_type = \"CombinedINR\"` instead of `config[\"model_type\"] = \"CombinedINR\"`). You can also just use a dictionary instead.\n",
    "\n",
    "Then we'll use the tools from `common_jax_utils` to first get a model from this config so we can inspect it, and then just run the experiment specified by the config.\n",
    "\n",
    "Doing this in a config instead of hard coded might seem like extra work, but consider this:\n",
    "1. you can serialize this config as a json file or a yaml file to later get the same model and experimental settings back \n",
    "   so when you are experimenting with different architectures, if you just store the configs you've used, you can easily recreate previous results\n",
    "2. when we get to running hyper parameter sweeps, you can easily get these configs (with a pick for the varying hyper parameters) from wandb\n",
    "   and then run an experiment specified by that config on any machine you want, e.g. on Snellius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:08.286276794Z",
     "start_time": "2025-01-30T11:32:07.809052257Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "# first we specify what the model should look like\n",
    "config.architecture = './model_components'  # module containing all relevant classes for architectures\n",
    "# NB if the classes relevant for creating the model are spread over multiple modules, this is no problem\n",
    "# let config.architecture be the module that contains the \"main\" model class, and for all other components just specify the module\n",
    "# or specify the other modules as default modules to the tools in common_jax_utils.run_utils\n",
    "config.model_type = 'inr_modules.CombinedINR'\n",
    "\n",
    "config.model_config = Config()\n",
    "config.model_config.in_size = 3\n",
    "config.model_config.out_size = 1\n",
    "config.model_config.terms = [  # CombinedINR uses multiple MLPs and returns the sum of their outputs. These 'terms' are the MLPs\n",
    "    ('inr_modules.MLPINR.from_config',{\n",
    "        'hidden_size': 512,\n",
    "        'num_layers': 3,\n",
    "        'layer_type': 'inr_layers.SirenLayer',\n",
    "        'num_splits': 3,\n",
    "        'activation_kwargs': {'w0':12.},#{'inverse_scale': 5.},\n",
    "        'initialization_scheme':'initialization_schemes.siren_scheme',\n",
    "        'initialization_scheme_kwargs': {'w0': 12.},\n",
    "        'positional_encoding_layer': ('state_test_objects.py', 'CountingIdentity'),\n",
    "        # 'post_processor': 'model_components.auxiliary.squeeze_array',\n",
    "    }),\n",
    "    # ('inr_modules.MLPINR.from_config',{\n",
    "    #     'hidden_size': 1024,\n",
    "    #     'num_layers': 2,\n",
    "    #     'num_splits': 1,\n",
    "    #     'layer_type': 'inr_layers.GaussianINRLayer',\n",
    "    #     'use_complex': False,\n",
    "    #     'activation_kwargs': {'inverse_scale': 1},\n",
    "    # })\n",
    "]\n",
    "\n",
    "# next, we set up the training loop, including the 'target_function' that we want to mimic\n",
    "config.trainer_module = './inr_utils/'  # similarly to config.architecture above, here we just specify in what module to look for objects by default\n",
    "config.trainer_type = 'training.train_with_dataloader_scan'\n",
    "\n",
    "\n",
    "config.dataloader = 'sdf.SDFDataLoader'\n",
    "\n",
    "config.dataloader_config = {\n",
    "    \"sdf_name\": \"Armadillo\",\n",
    "    \"batch_size\": 100,\n",
    "    \"keep_aspect_ratio\":False\n",
    "\n",
    "}\n",
    "\n",
    "config.num_cycles = 20\n",
    "config.steps_per_cycle = 100\n",
    "\n",
    "\n",
    "config.loss_evaluator = \"losses.SDFLossEvaluator\"\n",
    "\n",
    "\n",
    "config.target_function = 'sdf.SDFDataLoader' #see when config. losseval\n",
    "config.target_function_config = {\n",
    "    \"sdf_name\": \"Armadillo\",\n",
    "    \"batch_size\": 100,\n",
    "    \"keep_aspect_ratio\":False,\n",
    "\n",
    "}\n",
    "\n",
    "config.state_update_function = ('state_test_objects.py', 'counter_updater')\n",
    "\n",
    "config.optimizer = 'adam'  # we'll have to add optax to the additional default modules later\n",
    "config.optimizer_config = {\n",
    "    'learning_rate': 1.5e-4\n",
    "}\n",
    "config.steps = 20000 #changed from 40000\n",
    "config.use_wandb = True\n",
    "\n",
    "# now we want some extra things, like logging, to happen during training\n",
    "# the inr_utils.training.train_inr function allows for this through callbacks.\n",
    "# The callbacks we want to use can be found in inr_utils.callbacks\n",
    "config.after_cycle_callback = 'callbacks.ComposedCallback'\n",
    "config.after_cycle_callback_config = {\n",
    "    'callbacks':[\n",
    "        ('callbacks.print_loss', {'after_every':1}),  # only print the loss every 400th step\n",
    "        'callbacks.report_loss',  # but log the loss to wandb after every step\n",
    "        ('callbacks.MetricCollectingCallback', # this thing will help us collect metrics and log images to wandb\n",
    "             {'metric_collector':'metrics.MetricCollector'}\n",
    "        ),\n",
    "        'callbacks.raise_error_on_nan'  # stop training if the loss becomes NaN\n",
    "    ],\n",
    "    'show_logs': False\n",
    "}\n",
    "\n",
    "config.after_training_callback = ('state_test_objects.py', 'after_training_callback')\n",
    "\n",
    "config.metric_collector_config = {  # the metrics for MetricCollectingCallback / metrics.MetricCollector\n",
    "    'metrics':[\n",
    "        ('metrics.JaccardIndexSDF', {\n",
    "            'frequency':'every_n_batches',\n",
    "            'grid_resolution': 100,\n",
    "            'num_dims': 3,\n",
    "        }),  \n",
    "        # todo add view rendering here\n",
    "\n",
    "    ],\n",
    "    'batch_frequency': 5,  # compute all of these metrics every 400 batches\n",
    "    'epoch_frequency': 1  # not actually used\n",
    "}\n",
    "\n",
    "#config.after_training_callback = None  # don't care for one now, but you could have this e.g. store some nice loss plots if you're not using wandb \n",
    "config.optimizer_state = None  # we're starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:09.648230019Z",
     "start_time": "2025-01-30T11:32:07.815000551Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's first see if we get the correct model\n",
    "try:\n",
    "    inr = cju.run_utils.get_model_from_config_and_key(\n",
    "        prng_key=next(key_gen),\n",
    "        config=config,\n",
    "        model_sub_config_name_base='model',\n",
    "        add_model_module_to_architecture_default_module=False, # since the model is already in the default module specified by 'architecture',\n",
    "    )\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)\n",
    "    print('\\n')\n",
    "    pdb.post_mortem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:09.649650872Z",
     "start_time": "2025-01-30T11:32:09.625766423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "CombinedINR(\n  terms=(\n    MLPINR(\n      layers=(\n        CountingIdentity(\n          _embedding_matrix=f32[3],\n          state_index=StateIndex(\n            marker=<object object at 0x7f671926bb20>,\n            init=i32[]\n          )\n        ),\n        SirenLayer(\n          weights=f32[512,3],\n          biases=f32[512],\n          activation_kwargs={'w0': 12.0}\n        ),\n        Linear(weights=f32[1,512], biases=f32[1], activation_kwargs={})\n      )\n    ),\n  ),\n  post_processor=<function real_part>\n)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:10.133792175Z",
     "start_time": "2025-01-30T11:32:09.631104696Z"
    }
   },
   "outputs": [],
   "source": [
    "# check that it works properly\n",
    "try:\n",
    "    inr(jnp.zeros(3))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)\n",
    "    print('\\n')\n",
    "    pdb.post_mortem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:10.411567868Z",
     "start_time": "2025-01-30T11:32:10.089855347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(Array([0.48826963], dtype=float32), None)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inr(jnp.zeros(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:10.411911358Z",
     "start_time": "2025-01-30T11:32:10.155184066Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:11.552166782Z",
     "start_time": "2025-01-30T11:32:10.163095508Z"
    }
   },
   "outputs": [],
   "source": [
    "# next we get the experiment from the config using common_jax_utils.run_utils.get_experiment_from_config_and_key\n",
    "experiment = cju.run_utils.get_experiment_from_config_and_key(\n",
    "    prng_key=next(key_gen),\n",
    "    config=config,\n",
    "    model_kwarg_in_trainer='inr',\n",
    "    model_sub_config_name_base='model',  # so it looks for \"model_config\" in config\n",
    "    trainer_default_module_key='trainer_module',  # so it knows to get the module specified by config.trainer_module\n",
    "    additional_trainer_default_modules=[optax],  # remember the don't forget to add optax to the default modules? This is that \n",
    "    add_model_module_to_architecture_default_module=False,\n",
    "    initialize=False  # don't run the experiment yet, we want to use wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:32:11.553445885Z",
     "start_time": "2025-01-30T11:32:11.518012553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "PostponedInitialization(cls=train_with_dataloader_scan, kwargs={'loss_evaluator': PostponedInitialization(cls=SDFLossEvaluator, kwargs={'state_update_function': <function counter_updater at 0x7f6536ab7be0>}, missing_args=[]), 'dataloader': PostponedInitialization(cls=SDFDataLoader, kwargs={'sdf_name': 'Armadillo', 'batch_size': 100, 'keep_aspect_ratio': False, 'key': Array([1722811570, 3826931003], dtype=uint32)}, missing_args=[]), 'optimizer': PostponedInitialization(cls=adam, kwargs={'learning_rate': 0.00015, 'b1': 0.9, 'b2': 0.999, 'eps': 1e-08, 'eps_root': 0.0, 'mu_dtype': None, 'nesterov': False}, missing_args=[]), 'steps_per_cycle': 100, 'num_cycles': 20, 'use_wandb': True, 'after_cycle_callback': PostponedInitialization(cls=ComposedCallback, kwargs={'callbacks': [functools.partial(<function print_loss at 0x7f6536ab52d0>, after_every=1), <function report_loss at 0x7f6536ab55a0>, PostponedInitialization(cls=MetricCollectingCallback, kwargs={'metric_collector': PostponedInitialization(cls=MetricCollector, kwargs={'metrics': [PostponedInitialization(cls=JaccardIndexSDF, kwargs={'grid_resolution': 100, 'num_dims': 3, 'target_function': PostponedInitialization(cls=SDFDataLoader, kwargs={'sdf_name': 'Armadillo', 'batch_size': 100, 'keep_aspect_ratio': False, 'key': Array([ 217821282, 1145812168], dtype=uint32)}, missing_args=[])}, missing_args=[])], 'batch_frequency': 400, 'epoch_frequency': 1}, missing_args=[])}, missing_args=[]), <function raise_error_on_nan at 0x7f6536ab5750>], 'show_logs': False, 'use_wandb': True, 'display_func': <function pprint at 0x7f6775b11a20>}, missing_args=[]), 'after_training_callback': <function after_training_callback at 0x7f6536af0040>, 'optimizer_state': None, 'state_initialization_function': <function initialize_state at 0x7f6536ab5cf0>, 'state': None, 'inr': PostponedInitialization(cls=CombinedINR, kwargs={'terms': [PostponedInitialization(cls=from_config, kwargs={'hidden_size': 512, 'num_layers': 3, 'layer_type': <class 'model_components.inr_layers.SirenLayer'>, 'activation_kwargs': {'w0': 12.0}, 'initialization_scheme': <function siren_scheme at 0x7f67140ec670>, 'initialization_scheme_kwargs': {'w0': 12.0}, 'positional_encoding_layer': PostponedInitialization(cls=CountingIdentity, kwargs={}, missing_args=[]), 'num_splits': 3, 'post_processor': None, 'in_size': 3, 'out_size': 1, 'key': Array([3941762975, 2946414623], dtype=uint32)}, missing_args=[])], 'post_processor': <function real_part at 0x7f671409c5e0>}, missing_args=[])}, missing_args=[])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:35:49.371624Z",
     "start_time": "2025-01-30T11:32:11.526900451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.19.4"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/ovindar/PycharmProjects/INR_BEP/wandb/run-20250130_123211-qtqa7ly4</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/bep-circle/inr_edu_24/runs/qtqa7ly4' target=\"_blank\">devout-forest-144</a></strong> to <a href='https://wandb.ai/bep-circle/inr_edu_24' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/bep-circle/inr_edu_24' target=\"_blank\">https://wandb.ai/bep-circle/inr_edu_24</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/bep-circle/inr_edu_24/runs/qtqa7ly4' target=\"_blank\">https://wandb.ai/bep-circle/inr_edu_24/runs/qtqa7ly4</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 1 is 386.7723388671875.\n",
      "Loss at step 2 is 51.17979431152344.\n",
      "Loss at step 3 is 56.88624954223633.\n",
      "Loss at step 4 is 51.19890594482422.\n",
      "Loss at step 5 is 47.4002571105957.\n",
      "Loss at step 6 is 49.3947639465332.\n",
      "Loss at step 7 is 47.98609161376953.\n",
      "Loss at step 8 is 48.3199462890625.\n",
      "Loss at step 9 is 48.88901901245117.\n",
      "Loss at step 10 is 48.65013122558594.\n",
      "Loss at step 11 is 45.168983459472656.\n",
      "Loss at step 12 is 45.698699951171875.\n",
      "Loss at step 13 is 45.33483123779297.\n",
      "Loss at step 14 is 50.70302200317383.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_16627/2046111061.py\", line 8, in <module>\n",
      "    results = experiment.initialize()\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/common_dl_utils/config_realization.py\", line 195, in initialize\n",
      "    return cls(**processed_self_kwargs)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/inr_utils/training.py\", line 417, in train_with_dataloader_scan\n",
      "    batches = [next(dataloader_iter) for _ in range(steps_per_cycle)]\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/inr_utils/training.py\", line 417, in <listcomp>\n",
      "    batches = [next(dataloader_iter) for _ in range(steps_per_cycle)]\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/inr_utils/sdf.py\", line 73, in __iter__\n",
      "    jax.device_put(coords, self._gpu),\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/api.py\", line 2301, in device_put\n",
      "    out_flat = dispatch.device_put_p.bind(\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/core.py\", line 463, in bind\n",
      "    return self.bind_with_trace(prev_trace, args, params)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/core.py\", line 468, in bind_with_trace\n",
      "    return trace.process_primitive(self, args, params)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/core.py\", line 954, in process_primitive\n",
      "    return primitive.impl(*args, **params)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py\", line 497, in _batched_device_put_impl\n",
      "    y = _device_put_impl(x, device=device, src=src, copy=cp)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py\", line 486, in _device_put_impl\n",
      "    return _device_put_sharding_impl(x, aval, device, copy)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py\", line 442, in _device_put_sharding_impl\n",
      "    return pxla.batched_device_put(aval, SingleDeviceSharding(device), [x],\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py\", line 244, in batched_device_put\n",
      "    return xc.batched_device_put(aval, sharding, xs, list(devices), committed)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/profiler.py\", line 333, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/array.py\", line 627, in _value\n",
      "    self._npy_value = self._single_device_array_to_np_array()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_within_epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_within_epoch</td><td>14</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>50.70302</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">devout-forest-144</strong> at: <a href='https://wandb.ai/bep-circle/inr_edu_24/runs/qtqa7ly4' target=\"_blank\">https://wandb.ai/bep-circle/inr_edu_24/runs/qtqa7ly4</a><br> View project at: <a href='https://wandb.ai/bep-circle/inr_edu_24' target=\"_blank\">https://wandb.ai/bep-circle/inr_edu_24</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20250130_123211-qtqa7ly4/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 8\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m wandb\u001B[38;5;241m.\u001B[39minit(\n\u001B[1;32m      4\u001B[0m         project\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minr_edu_24\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      5\u001B[0m         notes\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m      6\u001B[0m         tags\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      7\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m run:\n\u001B[0;32m----> 8\u001B[0m         results \u001B[38;5;241m=\u001B[39m \u001B[43mexperiment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minitialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     10\u001B[0m     traceback\u001B[38;5;241m.\u001B[39mprint_exc()\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/common_dl_utils/config_realization.py:195\u001B[0m, in \u001B[0;36mPostponedInitialization.initialize\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    193\u001B[0m processed_self_kwargs\u001B[38;5;241m.\u001B[39mupdate(processed_kwargs)\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m _internal_utils\u001B[38;5;241m.\u001B[39msignature_to_var_keyword(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcls, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mneeds_wrapping \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcls\n\u001B[0;32m--> 195\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mprocessed_self_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/inr_utils/training.py:417\u001B[0m, in \u001B[0;36mtrain_with_dataloader_scan\u001B[0;34m(inr, loss_evaluator, dataloader, optimizer, steps_per_cycle, num_cycles, use_wandb, after_cycle_callback, after_training_callback, optimizer_state, state_initialization_function, state)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;66;03m# import time\u001B[39;00m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cycle \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_cycles):\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;66;03m# t0 = time.time()\u001B[39;00m\n\u001B[0;32m--> 417\u001B[0m     batches \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mnext\u001B[39m(dataloader_iter) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(steps_per_cycle)]\n\u001B[1;32m    418\u001B[0m     batches \u001B[38;5;241m=\u001B[39m stack_trees(batches)\n\u001B[1;32m    419\u001B[0m     \u001B[38;5;66;03m# jax.block_until_ready(batches)\u001B[39;00m\n\u001B[1;32m    420\u001B[0m     \u001B[38;5;66;03m# t1 = time.time()\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/inr_utils/training.py:417\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    413\u001B[0m \u001B[38;5;66;03m# import time\u001B[39;00m\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m cycle \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_cycles):\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;66;03m# t0 = time.time()\u001B[39;00m\n\u001B[0;32m--> 417\u001B[0m     batches \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdataloader_iter\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(steps_per_cycle)]\n\u001B[1;32m    418\u001B[0m     batches \u001B[38;5;241m=\u001B[39m stack_trees(batches)\n\u001B[1;32m    419\u001B[0m     \u001B[38;5;66;03m# jax.block_until_ready(batches)\u001B[39;00m\n\u001B[1;32m    420\u001B[0m     \u001B[38;5;66;03m# t1 = time.time()\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/inr_utils/sdf.py:73\u001B[0m, in \u001B[0;36mSDFDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     68\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(key_gen)\n\u001B[1;32m     70\u001B[0m coords, normals, sdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msample(key)\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m (\n\u001B[0;32m---> 73\u001B[0m     \u001B[43mjax\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_put\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcoords\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gpu\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m     74\u001B[0m     jax\u001B[38;5;241m.\u001B[39mdevice_put(normals, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gpu),\n\u001B[1;32m     75\u001B[0m     jax\u001B[38;5;241m.\u001B[39mdevice_put(sdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gpu)\n\u001B[1;32m     76\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/api.py:2301\u001B[0m, in \u001B[0;36mdevice_put\u001B[0;34m(x, device, src, donate, may_alias)\u001B[0m\n\u001B[1;32m   2299\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m xf, d \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(x_flat, device_flat):  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   2300\u001B[0m   _check_sharding(shaped_abstractify(xf), d)\n\u001B[0;32m-> 2301\u001B[0m out_flat \u001B[38;5;241m=\u001B[39m \u001B[43mdispatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice_put_p\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbind\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2302\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mx_flat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice_flat\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrcs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msrc_flat\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2303\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy_semantics\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy_semantics\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2304\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tree_unflatten(treedef, out_flat)\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/core.py:463\u001B[0m, in \u001B[0;36mPrimitive.bind\u001B[0;34m(self, *args, **params)\u001B[0m\n\u001B[1;32m    461\u001B[0m trace_ctx\u001B[38;5;241m.\u001B[39mset_trace(eval_trace)\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 463\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbind_with_trace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprev_trace\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    465\u001B[0m   trace_ctx\u001B[38;5;241m.\u001B[39mset_trace(prev_trace)\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/core.py:468\u001B[0m, in \u001B[0;36mPrimitive.bind_with_trace\u001B[0;34m(self, trace, args, params)\u001B[0m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mbind_with_trace\u001B[39m(\u001B[38;5;28mself\u001B[39m, trace, args, params):\n\u001B[0;32m--> 468\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtrace\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprocess_primitive\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/core.py:954\u001B[0m, in \u001B[0;36mEvalTrace.process_primitive\u001B[0;34m(self, primitive, args, params)\u001B[0m\n\u001B[1;32m    952\u001B[0m       \u001B[38;5;28;01mreturn\u001B[39;00m primitive\u001B[38;5;241m.\u001B[39mbind_with_trace(arg\u001B[38;5;241m.\u001B[39m_trace, args, params)\n\u001B[1;32m    953\u001B[0m check_eval_args(args)\n\u001B[0;32m--> 954\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprimitive\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimpl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py:497\u001B[0m, in \u001B[0;36m_batched_device_put_impl\u001B[0;34m(devices, srcs, copy_semantics, *xs)\u001B[0m\n\u001B[1;32m    495\u001B[0m dsa_indices, dsa_xs, dsa_shardings, dsa_copy_semantics \u001B[38;5;241m=\u001B[39m [], [], [], []\n\u001B[1;32m    496\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (x, device, src, cp) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(xs, devices, srcs, copy_semantics)):\n\u001B[0;32m--> 497\u001B[0m   y \u001B[38;5;241m=\u001B[39m \u001B[43m_device_put_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msrc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(y, _DeferredShardArg):\n\u001B[1;32m    499\u001B[0m     dsa_indices\u001B[38;5;241m.\u001B[39mappend(i)\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py:486\u001B[0m, in \u001B[0;36m_device_put_impl\u001B[0;34m(x, device, src, copy)\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _device_put_sharding_impl(x, aval, l\u001B[38;5;241m.\u001B[39msharding, copy)\n\u001B[1;32m    482\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m api\u001B[38;5;241m.\u001B[39mjit(\n\u001B[1;32m    483\u001B[0m       _identity_fn, out_shardings\u001B[38;5;241m=\u001B[39ml,\n\u001B[1;32m    484\u001B[0m       donate_argnums\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;241m==\u001B[39m CopySemantics\u001B[38;5;241m.\u001B[39mDONATE \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m))(x)\n\u001B[0;32m--> 486\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_device_put_sharding_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/dispatch.py:442\u001B[0m, in \u001B[0;36m_device_put_sharding_impl\u001B[0;34m(x, aval, device, copy)\u001B[0m\n\u001B[1;32m    440\u001B[0m   \u001B[38;5;28;01melif\u001B[39;00m is_single_device_sharding(x\u001B[38;5;241m.\u001B[39msharding):\n\u001B[1;32m    441\u001B[0m     device \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msharding\u001B[38;5;241m.\u001B[39m_device_assignment[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m device\n\u001B[0;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpxla\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatched_device_put\u001B[49m\u001B[43m(\u001B[49m\u001B[43maval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSingleDeviceSharding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43m[\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m sh \u001B[38;5;241m=\u001B[39m SingleDeviceSharding(pxla\u001B[38;5;241m.\u001B[39mget_default_device()\n\u001B[1;32m    446\u001B[0m                           \u001B[38;5;28;01mif\u001B[39;00m device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m device)\n\u001B[1;32m    447\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _DeferredShardArg(x, sh, aval, device \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, copy)\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:244\u001B[0m, in \u001B[0;36mbatched_device_put\u001B[0;34m(aval, sharding, xs, devices, committed)\u001B[0m\n\u001B[1;32m    241\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(bufs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mlen\u001B[39m(xs):\n\u001B[1;32m    242\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m array\u001B[38;5;241m.\u001B[39mArrayImpl(\n\u001B[1;32m    243\u001B[0m         aval, sharding, bufs, committed\u001B[38;5;241m=\u001B[39mcommitted, _skip_checks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 244\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mxc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatched_device_put\u001B[49m\u001B[43m(\u001B[49m\u001B[43maval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msharding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdevices\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcommitted\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    246\u001B[0m   util\u001B[38;5;241m.\u001B[39mtest_event(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatched_device_put_end\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/profiler.py:333\u001B[0m, in \u001B[0;36mannotate_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[1;32m    331\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    332\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m TraceAnnotation(name, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdecorator_kwargs):\n\u001B[0;32m--> 333\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    334\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m wrapper\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/array.py:627\u001B[0m, in \u001B[0;36mArrayImpl._value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    625\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    626\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_fully_replicated:\n\u001B[0;32m--> 627\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_single_device_array_to_np_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value\u001B[38;5;241m.\u001B[39mflags\u001B[38;5;241m.\u001B[39mwriteable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(np\u001B[38;5;241m.\u001B[39mndarray, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_npy_value)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# and we run the experiment while logging things to wandb\n",
    "try:\n",
    "    with wandb.init(\n",
    "        project='inr_edu_24',\n",
    "        notes='test',\n",
    "        tags=['test']\n",
    "    ) as run:\n",
    "        results = experiment.initialize()\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)\n",
    "    print('\\n')\n",
    "    pdb.post_mortem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-30T11:35:49.374118653Z"
    }
   },
   "outputs": [],
   "source": [
    "inr, losses, optimizer_state, state, loss_evaluator, additional_output = results\n",
    "inr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:35:49.381117765Z",
     "start_time": "2025-01-30T11:35:49.375487584Z"
    }
   },
   "outputs": [],
   "source": [
    "from state_test_objects import after_training_callback, CountingIdentity\n",
    "after_training_callback(losses, inr, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-30T11:35:49.378749690Z"
    }
   },
   "outputs": [],
   "source": [
    "inr.terms[0].layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-30T11:35:49.421191591Z"
    }
   },
   "outputs": [],
   "source": [
    "isinstance(inr.terms[0].layers[0], CountingIdentity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T11:35:49.441816385Z",
     "start_time": "2025-01-30T11:35:49.421484779Z"
    }
   },
   "outputs": [],
   "source": [
    "type(inr.terms[0].layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-30T11:35:49.421725564Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr_edu_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
