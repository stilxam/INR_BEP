{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:44.681556518Z",
     "start_time": "2025-01-07T15:18:42.284324930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmaxwell_litsios\u001B[0m (\u001B[33mbep-circle\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import traceback\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "import wandb\n",
    "import equinox as eqx\n",
    "\n",
    "from common_dl_utils.config_creation import Config\n",
    "import common_jax_utils as cju\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "key = jax.random.PRNGKey(12398)\n",
    "key_gen = cju.key_generator(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:44.682814884Z",
     "start_time": "2025-01-07T15:18:44.669621087Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "# first we specify what the model should look like\n",
    "config.architecture = './model_components'  # module containing all relevant classes for architectures\n",
    "# NB if the classes relevant for creating the model are spread over multiple modules, this is no problem\n",
    "# let config.architecture be the module that contains the \"main\" model class, and for all other components just specify the module\n",
    "# or specify the other modules as default modules to the tools in common_jax_utils.run_utils\n",
    "config.model_type = 'inr_modules.CombinedINR'\n",
    "\n",
    "config.model_config = Config()\n",
    "config.model_config.in_size = 2\n",
    "config.model_config.out_size = 1\n",
    "config.model_config.terms = [  # CombinedINR uses multiple MLPs and returns the sum of their outputs. These 'terms' are the MLPs\n",
    "    ('inr_modules.MLPINR.from_config',{\n",
    "        'hidden_size': 1028,\n",
    "        'num_layers': 5,\n",
    "        # 'layer_type': 'inr_layers.GaussianINRLayer',\n",
    "        'layer_type': 'inr_layers.ComplexWIRE',\n",
    "        'num_splits': 3,\n",
    "        'activation_kwargs': {'w0': 25., \"s0\":15},\n",
    "        'initialization_scheme':'initialization_schemes.siren_scheme',\n",
    "        'initialization_scheme_kwargs': {'w0': 12.},\n",
    "        'post_processor':'auxiliary.real_scalar'\n",
    "        #'positional_encoding_layer': ('inr_layers.ClassicalPositionalEncoding.from_config', {'num_frequencies': 10}),\n",
    "    }),\n",
    "    # ('inr_modules.MLPINR.from_config',{\n",
    "    #     'hidden_size': 1024,\n",
    "    #     'num_layers': 2,\n",
    "    #     'num_splits': 1,\n",
    "    #     'layer_type': 'inr_layers.GaussianINRLayer',\n",
    "    #     'use_complex': False,\n",
    "    #     'activation_kwargs': {'inverse_scale': 1},\n",
    "    # })\n",
    "]\n",
    "#config.model_config.post_processor = lambda x: x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:46.078369815Z",
     "start_time": "2025-01-07T15:18:44.673353902Z"
    }
   },
   "outputs": [],
   "source": [
    "# let's first see if we get the correct model\n",
    "try:\n",
    "    inr = cju.run_utils.get_model_from_config_and_key(\n",
    "        prng_key=next(key_gen),\n",
    "        config=config,\n",
    "        model_sub_config_name_base='model',\n",
    "        add_model_module_to_architecture_default_module=False, # since the model is already in the default module specified by 'architecture',\n",
    "    )\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)\n",
    "    print('\\n')\n",
    "    pdb.post_mortem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:46.118842153Z",
     "start_time": "2025-01-07T15:18:46.084036795Z"
    }
   },
   "outputs": [],
   "source": [
    "def apply_inr(inr, location):\n",
    "    return inr(location)\n",
    "\n",
    "inr_grad = eqx.filter_grad(apply_inr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:48.300018954Z",
     "start_time": "2025-01-07T15:18:46.088464076Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ovindar/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/lax/lax.py:3458: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  x_bar = _convert_element_type(x_bar, x.aval.dtype, x.aval.weak_type)\n"
     ]
    },
    {
     "data": {
      "text/plain": "CombinedINR(\n  terms=(\n    MLPINR(\n      layers=(\n        ComplexWIRE(\n          weights=f32[1028,2],\n          biases=f32[1028],\n          activation_kwargs={'s0': 15, 'w0': 25.0}\n        ),\n        ComplexWIRE(\n          weights=f32[1028,1028],\n          biases=f32[1028],\n          activation_kwargs={'s0': 15, 'w0': 25.0}\n        ),\n        ComplexWIRE(\n          weights=f32[1028,1028],\n          biases=f32[1028],\n          activation_kwargs={'s0': 15, 'w0': 25.0}\n        ),\n        ComplexWIRE(\n          weights=f32[1028,1028],\n          biases=f32[1028],\n          activation_kwargs={'s0': 15, 'w0': 25.0}\n        ),\n        Linear(weights=f32[1,1028], biases=f32[1], activation_kwargs={}),\n        Lambda(fn=None)\n      )\n    ),\n  ),\n  post_processor=None\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inr_grad(inr, jnp.array([0.1, 0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:48.300286598Z",
     "start_time": "2025-01-07T15:18:48.167472797Z"
    }
   },
   "outputs": [],
   "source": [
    "def tree_inner_product(tree_1, tree_2):\n",
    "    component_wise = jax.tree.map(lambda x, y: jnp.sum(x*y), tree_1, tree_2)\n",
    "    return sum(jax.tree.leaves(component_wise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:48.640975300Z",
     "start_time": "2025-01-07T15:18:48.171238785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Array(1.9876883, dtype=float32)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_inner_product(\n",
    "    inr_grad(inr, jnp.array([0.1, 0.75])),\n",
    "    inr_grad(inr, jnp.array([0.2, 0.65]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:18:48.649017600Z",
     "start_time": "2025-01-07T15:18:48.640464131Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def ntk_single(inr, loc_1, loc_2):\n",
    "    return tree_inner_product(\n",
    "    inr_grad(inr, loc_1),\n",
    "    inr_grad(inr, loc_2)\n",
    ")\n",
    "\n",
    "def _ntk_single(inr, loc1loc2):\n",
    "    channels = loc1loc2.shape[-1]//2\n",
    "    loc_1 = loc1loc2[:channels]\n",
    "    loc_2 = loc1loc2[channels:]\n",
    "    return ntk_single(inr, loc_1, loc_2)\n",
    "\n",
    "def ntk_array(inr, locations, batch_size):\n",
    "    channels = locations.shape[-1]\n",
    "    locations = locations.reshape(-1, channels)\n",
    "\n",
    "    #first on the lower triangle\n",
    "    loc_1_indices, loc_2_indices = jnp.tril_indices(locations.shape[0])\n",
    "    loc_1 = locations[loc_1_indices]\n",
    "    loc_2 = locations[loc_2_indices]\n",
    "    loc_1_loc_2 = jnp.concatenate([loc_1, loc_2], -1)\n",
    "    \n",
    "    apply_ntk_single_batch = lambda batch: jax.vmap(_ntk_single, (None, 0))(inr, batch)\n",
    "    batches = loc_1_loc_2.reshape((-1, batch_size, 2*channels))\n",
    "    print(f\"{batches.shape=}\")\n",
    "    num_batches = batches.shape[0]\n",
    "    resulting_batches = jax.lax.map(apply_ntk_single_batch, batches)\n",
    "    results_flat = resulting_batches.reshape(num_batches*batch_size)\n",
    "\n",
    "    return results_flat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:20:43.500578330Z",
     "start_time": "2025-01-07T15:20:43.453628501Z"
    }
   },
   "outputs": [],
   "source": [
    "from inr_utils.images import make_lin_grid\n",
    "locations = make_lin_grid(0., 1., (28, 28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:21:07.489598694Z",
     "start_time": "2025-01-07T15:21:07.410875915Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot reshape array of shape (307720, 4) (size 1230880) into shape (-1, 112, 4) because the product of specified axis sizes (448) does not evenly divide 1230880",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[19], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m kernel \u001B[38;5;241m=\u001B[39m \u001B[43mntk_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43minr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocations\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 24\u001B[0m, in \u001B[0;36mntk_array\u001B[0;34m(inr, locations, batch_size)\u001B[0m\n\u001B[1;32m     21\u001B[0m loc_1_loc_2 \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mconcatenate([loc_1, loc_2], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     23\u001B[0m apply_ntk_single_batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m batch: jax\u001B[38;5;241m.\u001B[39mvmap(_ntk_single, (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m0\u001B[39m))(inr, batch)\n\u001B[0;32m---> 24\u001B[0m batches \u001B[38;5;241m=\u001B[39m \u001B[43mloc_1_loc_2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mchannels\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbatches\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m=}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     26\u001B[0m num_batches \u001B[38;5;241m=\u001B[39m batches\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:456\u001B[0m, in \u001B[0;36m_compute_newshape\u001B[0;34m(arr, newshape)\u001B[0m\n\u001B[1;32m    453\u001B[0m other_sizes \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m*\u001B[39mnewshape[:i], \u001B[38;5;241m*\u001B[39mnewshape[i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m:])\n\u001B[1;32m    454\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mall\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(d, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m d \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m*\u001B[39marr\u001B[38;5;241m.\u001B[39mshape, \u001B[38;5;241m*\u001B[39mother_sizes)) \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m    455\u001B[0m     arr\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m%\u001B[39m math\u001B[38;5;241m.\u001B[39mprod(other_sizes) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m--> 456\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot reshape array of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marr\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (size \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marr\u001B[38;5;241m.\u001B[39msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    457\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minto shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00morig_newshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because the product of \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    458\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecified axis sizes (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmath\u001B[38;5;241m.\u001B[39mprod(other_sizes)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) does \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    459\u001B[0m                   \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot evenly divide \u001B[39m\u001B[38;5;132;01m{\u001B[39;00marr\u001B[38;5;241m.\u001B[39msize\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    460\u001B[0m sz \u001B[38;5;241m=\u001B[39m core\u001B[38;5;241m.\u001B[39mcancel_divide_tracers(arr\u001B[38;5;241m.\u001B[39mshape, other_sizes)\n\u001B[1;32m    461\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sz \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mTypeError\u001B[0m: cannot reshape array of shape (307720, 4) (size 1230880) into shape (-1, 112, 4) because the product of specified axis sizes (448) does not evenly divide 1230880"
     ]
    }
   ],
   "source": [
    "kernel = ntk_array(inr, locations, 4*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:19:02.130896760Z",
     "start_time": "2025-01-07T15:19:02.083252811Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-07T15:21:33.598483137Z",
     "start_time": "2025-01-07T15:21:33.507614282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "10990.0"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1230880/(4*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inr_edu_24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
