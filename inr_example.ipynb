{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of training an INR locally\n",
    "This notebook provides an example of how to create an INR and train it locally using the tools in this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:55:22.968569596Z",
     "start_time": "2025-01-06T14:55:22.925237450Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msimon-martinus-koop\u001b[0m (\u001b[33mnld\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "2025-01-30 19:29:07.444495: W external/xla/xla/service/gpu/nvptx_compiler.cc:893] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.6.68. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import traceback\n",
    "\n",
    "import jax\n",
    "from jax import numpy as jnp\n",
    "import optax\n",
    "import wandb\n",
    "\n",
    "from common_dl_utils.config_creation import Config\n",
    "import common_jax_utils as cju\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "key = jax.random.PRNGKey(12398)\n",
    "key_gen = cju.key_generator(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:55:23.553170506Z",
     "start_time": "2025-01-06T14:55:23.447043302Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train a single INR on `example_data/parrot.png`. We'll use the `CombinedINR` clas from `model_components.inr_modules` together with the `SirenLayer` and `GaussianINRLayer` from `model_components.inr_layers` for the model, and we'll train it using the tools from `inr_utils`.\n",
    "\n",
    "To do all of this, basically we only need to create a config. We'll use the `common_dl_utils.config_creation.Config` class for this, but this is basically just a dictionary that allows for attribute access-like acces of its elements (so we can do `config.model_type = \"CombinedINR\"` instead of `config[\"model_type\"] = \"CombinedINR\"`). You can also just use a dictionary instead.\n",
    "\n",
    "Then we'll use the tools from `common_jax_utils` to first get a model from this config so we can inspect it, and then just run the experiment specified by the config.\n",
    "\n",
    "Doing this in a config instead of hard coded might seem like extra work, but consider this:\n",
    "1. you can serialize this config as a json file or a yaml file to later get the same model and experimental settings back \n",
    "   so when you are experimenting with different architectures, if you just store the configs you've used, you can easily recreate previous results\n",
    "2. when we get to running hyper parameter sweeps, you can easily get these configs (with a pick for the varying hyper parameters) from wandb\n",
    "   and then run an experiment specified by that config on any machine you want, e.g. on Snellius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:55:24.410408058Z",
     "start_time": "2025-01-06T14:55:24.393999841Z"
    }
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "# first we specify what the model should look like\n",
    "config.architecture = './model_components'  # module containing all relevant classes for architectures\n",
    "# NB if the classes relevant for creating the model are spread over multiple modules, this is no problem\n",
    "# let config.architecture be the module that contains the \"main\" model class, and for all other components just specify the module\n",
    "# or specify the other modules as default modules to the tools in common_jax_utils.run_utils\n",
    "config.model_type = 'inr_modules.CombinedINR'\n",
    "\n",
    "config.model_config = Config()\n",
    "config.model_config.in_size = 2\n",
    "config.model_config.out_size = 3\n",
    "config.model_config.terms = [  # CombinedINR uses multiple MLPs and returns the sum of their outputs. These 'terms' are the MLPs\n",
    "    ('inr_modules.MLPINR.from_config',{\n",
    "        'hidden_size': 256,\n",
    "        'num_layers': 5,\n",
    "        'layer_type': 'inr_layers.SirenLayer',\n",
    "        'num_splits': 3,\n",
    "        'activation_kwargs': {'w0':12.},#{'inverse_scale': 5.},\n",
    "        'initialization_scheme':'initialization_schemes.siren_scheme',\n",
    "        'initialization_scheme_kwargs': {'w0': 12.},\n",
    "        'positional_encoding_layer': ('state_test_objects.py', 'CountingIdentity'),\n",
    "    }),\n",
    "    ('inr_modules.MLPINR.from_config', {\n",
    "        'hidden_size': 1024,\n",
    "        'num_layers': 2,\n",
    "        'layer_type': 'inr_layers.FinerLayer',\n",
    "        'num_splits': 1,\n",
    "        'activation_kwargs': {'w0': 30.},\n",
    "        'initialization_scheme': 'initialization_schemes.finer_scheme',\n",
    "        'initialization_scheme_kwargs': {'bias_k': 10},\n",
    "        # 'positional_encoding_layer': ('state_test_objects.py', 'CountingIdentity'),\n",
    "    }),\n",
    "    # ('inr_modules.MLPINR.from_config',{\n",
    "    #     'hidden_size': 1024,\n",
    "    #     'num_layers': 2,\n",
    "    #     'num_splits': 1,\n",
    "    #     'layer_type': 'inr_layers.GaussianINRLayer',\n",
    "    #     'use_complex': False,\n",
    "    #     'activation_kwargs': {'inverse_scale': 1},\n",
    "    # })\n",
    "    \n",
    "]\n",
    "\n",
    "# next, we set up the training loop, including the 'target_function' that we want to mimic\n",
    "config.trainer_module = './inr_utils/'  # similarly to config.architecture above, here we just specify in what module to look for objects by default\n",
    "config.trainer_type = 'training.train_inr'\n",
    "config.loss_evaluator = 'losses.PointWiseLossEvaluator'\n",
    "config.target_function = 'images.ContinuousImage'\n",
    "config.target_function_config = {\n",
    "    'image': './example_data/parrot.png',\n",
    "    'scale_to_01': True,\n",
    "    'interpolation_method': 'images.make_piece_wise_constant_interpolation',\n",
    "    'data_index': None\n",
    "}\n",
    "config.loss_function = 'losses.scaled_mse_loss'\n",
    "config.state_update_function = ('state_test_objects.py', 'counter_updater')\n",
    "config.sampler = ('sampling.GridSubsetSampler',{  # samples coordinates in a fixed grid, that should in this case coincide with the pixel locations in the image\n",
    "    'size': [2040, 1356],\n",
    "    'batch_size': 2000,\n",
    "    'allow_duplicates': False,\n",
    "})\n",
    "\n",
    "config.optimizer = 'adam'  # we'll have to add optax to the additional default modules later\n",
    "config.optimizer_config = {\n",
    "    'learning_rate': 1.5e-4\n",
    "}\n",
    "config.steps = 20000 #changed from 40000\n",
    "config.use_wandb = True\n",
    "\n",
    "# now we want some extra things, like logging, to happen during training\n",
    "# the inr_utils.training.train_inr function allows for this through callbacks.\n",
    "# The callbacks we want to use can be found in inr_utils.callbacks\n",
    "config.after_step_callback = 'callbacks.ComposedCallback'\n",
    "config.after_step_callback_config = {\n",
    "    'callbacks':[\n",
    "        ('callbacks.print_loss', {'after_every':400}),  # only print the loss every 400th step\n",
    "        'callbacks.report_loss',  # but log the loss to wandb after every step\n",
    "        ('callbacks.MetricCollectingCallback', # this thing will help us collect metrics and log images to wandb\n",
    "             {'metric_collector':'metrics.MetricCollector'}\n",
    "        ),\n",
    "        'callbacks.raise_error_on_nan'  # stop training if the loss becomes NaN\n",
    "    ],\n",
    "    'show_logs': False\n",
    "}\n",
    "\n",
    "config.after_training_callback = ('state_test_objects.py', 'after_training_callback')\n",
    "\n",
    "config.metric_collector_config = {  # the metrics for MetricCollectingCallback / metrics.MetricCollector\n",
    "    'metrics':[\n",
    "        ('metrics.PlotOnGrid2D', {'grid': 256, 'batch_size':8*256, 'frequency':'every_n_batches'}),  \n",
    "        # ^ plots the image on this fixed grid so we can visually inspect the inr on wandb\n",
    "        ('metrics.MSEOnFixedGrid', {'grid': [2040, 1356], 'batch_size':2040, 'frequency': 'every_n_batches'})\n",
    "        # ^ compute the MSE with the actual image pixels\n",
    "    ],\n",
    "    'batch_frequency': 400,  # compute all of these metrics every 400 batches\n",
    "    'epoch_frequency': 1  # not actually used\n",
    "}\n",
    "\n",
    "#config.after_training_callback = None  # don't care for one now, but you could have this e.g. store some nice loss plots if you're not using wandb \n",
    "config.optimizer_state = None  # we're starting from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's first see if we get the correct model\n",
    "try:\n",
    "    inr = cju.run_utils.get_model_from_config_and_key(\n",
    "        prng_key=next(key_gen),\n",
    "        config=config,\n",
    "        model_sub_config_name_base='model',\n",
    "        add_model_module_to_architecture_default_module=False, # since the model is already in the default module specified by 'architecture',\n",
    "    )\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)\n",
    "    print('\\n')\n",
    "    pdb.post_mortem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-27T13:11:48.290828912Z",
     "start_time": "2024-11-27T13:11:48.207796154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedINR(\n",
       "  terms=(\n",
       "    MLPINR(\n",
       "      layers=(\n",
       "        CountingIdentity(\n",
       "          _embedding_matrix=f32[3],\n",
       "          state_index=StateIndex(\n",
       "            marker=<object object at 0x7a0c6c63fdf0>,\n",
       "            init=i32[]\n",
       "          )\n",
       "        ),\n",
       "        SirenLayer(\n",
       "          weights=f32[256,2],\n",
       "          biases=f32[256],\n",
       "          activation_kwargs={'w0': 12.0}\n",
       "        ),\n",
       "        SirenLayer(\n",
       "          weights=f32[256,256],\n",
       "          biases=f32[256],\n",
       "          activation_kwargs={'w0': 12.0}\n",
       "        ),\n",
       "        SirenLayer(\n",
       "          weights=f32[256,256],\n",
       "          biases=f32[256],\n",
       "          activation_kwargs={'w0': 12.0}\n",
       "        ),\n",
       "        Linear(weights=f32[3,256], biases=f32[3], activation_kwargs={})\n",
       "      )\n",
       "    ),\n",
       "  ),\n",
       "  post_processor=<function real_part>\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that it works properly\n",
    "try:\n",
    "    inr(jnp.zeros(2))\n",
    "except Exception as e:\n",
    "    traceback.print_exc()\n",
    "    print(e)\n",
    "    print('\\n')\n",
    "    pdb.post_mortem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we get the experiment from the config using common_jax_utils.run_utils.get_experiment_from_config_and_key\n",
    "experiment = cju.run_utils.get_experiment_from_config_and_key(\n",
    "    prng_key=next(key_gen),\n",
    "    config=config,\n",
    "    model_kwarg_in_trainer='inr',\n",
    "    model_sub_config_name_base='model',  # so it looks for \"model_config\" in config\n",
    "    trainer_default_module_key='trainer_module',  # so it knows to get the module specified by config.trainer_module\n",
    "    additional_trainer_default_modules=[optax],  # remember the don't forget to add optax to the default modules? This is that \n",
    "    add_model_module_to_architecture_default_module=False,\n",
    "    initialize=False  # don't run the experiment yet, we want to use wandb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostponedInitialization(cls=train_inr, kwargs={'loss_evaluator': PostponedInitialization(cls=PointWiseLossEvaluator, kwargs={'target_function': PostponedInitialization(cls=ContinuousImage, kwargs={'image': './example_data/parrot.png', 'scale_to_01': True, 'interpolation_method': <function make_piece_wise_constant_interpolation at 0x7a0c5546ca60>, 'data_index': None}, missing_args=[]), 'loss_function': <function scaled_mse_loss at 0x7a0c1c1fb400>, 'state_update_function': <function counter_updater at 0x7a0c1c242710>}, missing_args=[]), 'sampler': PostponedInitialization(cls=GridSubsetSampler, kwargs={'size': [2040, 1356], 'batch_size': 2000, 'allow_duplicates': False, 'min': 0.0, 'max': 1.0, 'num_dimensions': None, 'indexing': 'ij'}, missing_args=[]), 'optimizer': PostponedInitialization(cls=adam, kwargs={'learning_rate': 0.00015, 'b1': 0.9, 'b2': 0.999, 'eps': 1e-08, 'eps_root': 0.0, 'mu_dtype': None, 'nesterov': False}, missing_args=[]), 'steps': 20000, 'use_wandb': True, 'after_step_callback': PostponedInitialization(cls=ComposedCallback, kwargs={'callbacks': [functools.partial(<function print_loss at 0x7a0c1c20c430>, after_every=400), <function report_loss at 0x7a0c1c240160>, PostponedInitialization(cls=MetricCollectingCallback, kwargs={'metric_collector': PostponedInitialization(cls=MetricCollector, kwargs={'metrics': [PostponedInitialization(cls=PlotOnGrid2D, kwargs={'grid': 256, 'batch_size': 2048, 'frequency': 'every_n_batches', 'use_wandb': True}, missing_args=[]), PostponedInitialization(cls=MSEOnFixedGrid, kwargs={'grid': [2040, 1356], 'batch_size': 2040, 'frequency': 'every_n_batches', 'num_dims': None, 'target_function': PostponedInitialization(cls=ContinuousImage, kwargs={'image': './example_data/parrot.png', 'scale_to_01': True, 'interpolation_method': <function make_piece_wise_constant_interpolation at 0x7a0c5546ca60>, 'data_index': None}, missing_args=[])}, missing_args=[])], 'batch_frequency': 400, 'epoch_frequency': 1}, missing_args=[])}, missing_args=[]), <function raise_error_on_nan at 0x7a0c1c240310>], 'show_logs': False, 'use_wandb': True, 'display_func': <function pprint at 0x7a0cb7e11120>}, missing_args=[]), 'after_training_callback': <function after_training_callback at 0x7a0c1c2429e0>, 'optimizer_state': None, 'state_initialization_function': <function initialize_state at 0x7a0c1c240940>, 'state': None, 'inr': PostponedInitialization(cls=CombinedINR, kwargs={'terms': [PostponedInitialization(cls=from_config, kwargs={'hidden_size': 256, 'num_layers': 5, 'layer_type': <class 'model_components.inr_layers.SirenLayer'>, 'activation_kwargs': {'w0': 12.0}, 'initialization_scheme': <function siren_scheme at 0x7a0c5e729ab0>, 'initialization_scheme_kwargs': {'w0': 12.0}, 'positional_encoding_layer': PostponedInitialization(cls=CountingIdentity, kwargs={}, missing_args=[]), 'num_splits': 3, 'post_processor': None, 'in_size': 2, 'out_size': 3, 'key': Array([4177750840, 1613599438], dtype=uint32)}, missing_args=[])], 'post_processor': <function real_part at 0x7a0c6b85d6c0>}, missing_args=[]), 'key': Array([ 793826064, 3381256178], dtype=uint32)}, missing_args=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/simon/Documents/INR_BEP/wandb/run-20250130_192909-oija9uck</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nld/inr_edu_24/runs/oija9uck' target=\"_blank\">stellar-field-250</a></strong> to <a href='https://wandb.ai/nld/inr_edu_24' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nld/inr_edu_24' target=\"_blank\">https://wandb.ai/nld/inr_edu_24</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nld/inr_edu_24/runs/oija9uck' target=\"_blank\">https://wandb.ai/nld/inr_edu_24/runs/oija9uck</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0130 19:29:15.768497 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.768520 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.768528 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.768541 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.768546 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.768552 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.768610 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.768624 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.768631 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.768644 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.768650: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.769615 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.769626 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.769634 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.769650 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.769657 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.769665 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.769737 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.769756 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.769764 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.769779 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.769785: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.770721 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0245552, expected -0.18261\n",
      "E0130 19:29:15.770735 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344917, expected 0.513586\n",
      "E0130 19:29:15.770743 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593309, expected -0.810047\n",
      "E0130 19:29:15.770759 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126198, expected -0.26074\n",
      "E0130 19:29:15.770766 2673770 buffer_comparator.cc:157] Difference at 6406: 0.365433, expected 0.127136\n",
      "E0130 19:29:15.770774 2673770 buffer_comparator.cc:157] Difference at 7411: 0.272489, expected 0.135361\n",
      "E0130 19:29:15.770841 2673770 buffer_comparator.cc:157] Difference at 23116: 0.0235825, expected -0.128586\n",
      "E0130 19:29:15.770859 2673770 buffer_comparator.cc:157] Difference at 26084: -0.164776, expected 0.0703011\n",
      "E0130 19:29:15.770868 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0297012, expected -0.151157\n",
      "E0130 19:29:15.770883 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210636, expected -0.355889\n",
      "2025-01-30 19:29:15.770888: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.771777 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0245972, expected -0.18261\n",
      "E0130 19:29:15.771789 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344833, expected 0.513586\n",
      "E0130 19:29:15.771797 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593285, expected -0.810047\n",
      "E0130 19:29:15.771813 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126305, expected -0.26074\n",
      "E0130 19:29:15.771821 2673770 buffer_comparator.cc:157] Difference at 6406: 0.365238, expected 0.127136\n",
      "E0130 19:29:15.771828 2673770 buffer_comparator.cc:157] Difference at 7411: 0.272558, expected 0.135361\n",
      "E0130 19:29:15.771895 2673770 buffer_comparator.cc:157] Difference at 23116: 0.0235977, expected -0.128586\n",
      "E0130 19:29:15.771913 2673770 buffer_comparator.cc:157] Difference at 26084: -0.164879, expected 0.0703011\n",
      "E0130 19:29:15.771922 2673770 buffer_comparator.cc:157] Difference at 27192: -0.02948, expected -0.151157\n",
      "E0130 19:29:15.771937 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210617, expected -0.355889\n",
      "2025-01-30 19:29:15.771942: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.773144 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.773156 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.773164 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.773181 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.773188 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.773196 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.773263 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.773282 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.773291 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.773306 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.773311: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.774127 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0245552, expected -0.18261\n",
      "E0130 19:29:15.774141 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344917, expected 0.513586\n",
      "E0130 19:29:15.774149 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593309, expected -0.810047\n",
      "E0130 19:29:15.774165 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126198, expected -0.26074\n",
      "E0130 19:29:15.774172 2673770 buffer_comparator.cc:157] Difference at 6406: 0.365433, expected 0.127136\n",
      "E0130 19:29:15.774180 2673770 buffer_comparator.cc:157] Difference at 7411: 0.272489, expected 0.135361\n",
      "E0130 19:29:15.774247 2673770 buffer_comparator.cc:157] Difference at 23116: 0.0235825, expected -0.128586\n",
      "E0130 19:29:15.774265 2673770 buffer_comparator.cc:157] Difference at 26084: -0.164776, expected 0.0703011\n",
      "E0130 19:29:15.774274 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0297012, expected -0.151157\n",
      "E0130 19:29:15.774290 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210636, expected -0.355889\n",
      "2025-01-30 19:29:15.774295: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.775203 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.775217 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.775224 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.775240 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.775247 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.775254 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.775321 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.775339 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.775348 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.775363 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.775368: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.776318 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.776330 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.776337 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.776354 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.776361 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.776368 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.776436 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.776455 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.776464 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.776480 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.776485: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.777567 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.777581 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.777589 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.777605 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.777613 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.777620 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.777688 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.777712 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.777721 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.777736 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.777742: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.779037 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.779051 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.779058 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.779075 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.779082 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.779089 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.779157 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.779175 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.779184 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.779200 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.779205: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.780237 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.780249 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.780257 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.780273 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.780280 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.780288 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.780356 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.780374 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.780383 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.780398 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.780403: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.781537 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.781549 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.781557 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.781573 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.781581 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.781588 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.781656 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.781674 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.781683 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.781703 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.781709: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.782804 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0246429, expected -0.18261\n",
      "E0130 19:29:15.782819 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344866, expected 0.513586\n",
      "E0130 19:29:15.782827 2673770 buffer_comparator.cc:157] Difference at 2581: -0.59333, expected -0.810047\n",
      "E0130 19:29:15.782843 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126446, expected -0.26074\n",
      "E0130 19:29:15.782850 2673770 buffer_comparator.cc:157] Difference at 6406: 0.365242, expected 0.127136\n",
      "E0130 19:29:15.782858 2673770 buffer_comparator.cc:157] Difference at 7411: 0.272873, expected 0.135361\n",
      "E0130 19:29:15.782925 2673770 buffer_comparator.cc:157] Difference at 23116: 0.0237923, expected -0.128586\n",
      "E0130 19:29:15.782944 2673770 buffer_comparator.cc:157] Difference at 26084: -0.164783, expected 0.0703011\n",
      "E0130 19:29:15.782953 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0294781, expected -0.151157\n",
      "E0130 19:29:15.782969 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210523, expected -0.355889\n",
      "2025-01-30 19:29:15.782974: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n",
      "E0130 19:29:15.784638 2673770 buffer_comparator.cc:157] Difference at 1417: -0.0243073, expected -0.18261\n",
      "E0130 19:29:15.784652 2673770 buffer_comparator.cc:157] Difference at 1508: 0.344694, expected 0.513586\n",
      "E0130 19:29:15.784660 2673770 buffer_comparator.cc:157] Difference at 2581: -0.593427, expected -0.810047\n",
      "E0130 19:29:15.784677 2673770 buffer_comparator.cc:157] Difference at 5564: -0.126866, expected -0.26074\n",
      "E0130 19:29:15.784684 2673770 buffer_comparator.cc:157] Difference at 6406: 0.364695, expected 0.127136\n",
      "E0130 19:29:15.784691 2673770 buffer_comparator.cc:157] Difference at 7411: 0.273155, expected 0.135361\n",
      "E0130 19:29:15.784764 2673770 buffer_comparator.cc:157] Difference at 23116: 0.024056, expected -0.128586\n",
      "E0130 19:29:15.784783 2673770 buffer_comparator.cc:157] Difference at 26084: -0.16444, expected 0.0703011\n",
      "E0130 19:29:15.784791 2673770 buffer_comparator.cc:157] Difference at 27192: -0.0291781, expected -0.151157\n",
      "E0130 19:29:15.784807 2673770 buffer_comparator.cc:157] Difference at 30096: -0.210361, expected -0.355889\n",
      "2025-01-30 19:29:15.784812: E external/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc:982] Results do not match the reference. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at step 400 is 0.5142787098884583.\n",
      "Loss at step 800 is 0.35081350803375244.\n",
      "Loss at step 1200 is 0.3345959782600403.\n",
      "Loss at step 1600 is 0.28657975792884827.\n",
      "Loss at step 2000 is 0.26108095049858093.\n",
      "Loss at step 2400 is 0.22311286628246307.\n",
      "Loss at step 2800 is 0.23863017559051514.\n",
      "Loss at step 3200 is 0.2221357822418213.\n",
      "Loss at step 3600 is 0.21185436844825745.\n",
      "Loss at step 4000 is 0.23104257881641388.\n",
      "Loss at step 4400 is 0.19976644217967987.\n",
      "Loss at step 4800 is 0.20882192254066467.\n",
      "Loss at step 5200 is 0.2006462961435318.\n",
      "Loss at step 5600 is 0.17089790105819702.\n",
      "Loss at step 6000 is 0.1891220062971115.\n",
      "Loss at step 6400 is 0.16833193600177765.\n",
      "Loss at step 6800 is 0.19257108867168427.\n",
      "Loss at step 7200 is 0.17340613901615143.\n",
      "Loss at step 7600 is 0.16121916472911835.\n",
      "Loss at step 8000 is 0.16255123913288116.\n",
      "Loss at step 8400 is 0.16224181652069092.\n",
      "Loss at step 8800 is 0.16522616147994995.\n",
      "Loss at step 9200 is 0.15401692688465118.\n",
      "Loss at step 9600 is 0.17386244237422943.\n",
      "Loss at step 10000 is 0.15894906222820282.\n",
      "Loss at step 10400 is 0.15982531011104584.\n",
      "Loss at step 10800 is 0.14931462705135345.\n",
      "Loss at step 11200 is 0.15224161744117737.\n",
      "Loss at step 11600 is 0.13745343685150146.\n",
      "Loss at step 12000 is 0.14839062094688416.\n",
      "Loss at step 12400 is 0.15840567648410797.\n",
      "Loss at step 12800 is 0.12181863933801651.\n",
      "Loss at step 13200 is 0.15026609599590302.\n",
      "Loss at step 13600 is 0.14359214901924133.\n",
      "Loss at step 14000 is 0.14653313159942627.\n",
      "Loss at step 14400 is 0.138998344540596.\n",
      "Loss at step 14800 is 0.13295884430408478.\n",
      "Loss at step 15200 is 0.1427460014820099.\n",
      "Loss at step 15600 is 0.14513900876045227.\n",
      "Loss at step 16000 is 0.12592478096485138.\n",
      "Loss at step 16400 is 0.11354755610227585.\n",
      "Loss at step 16800 is 0.11168729513883591.\n",
      "Loss at step 17200 is 0.12150903791189194.\n",
      "Loss at step 17600 is 0.1225481852889061.\n",
      "Loss at step 18000 is 0.11887353658676147.\n",
      "Loss at step 18400 is 0.12276305258274078.\n",
      "Loss at step 18800 is 0.10799054056406021.\n",
      "Loss at step 19200 is 0.12551313638687134.\n",
      "Loss at step 19600 is 0.1358289122581482.\n",
      "Loss at step 20000 is 0.13037684559822083.\n",
      "Checking model and state for CountingIdentity layers\n",
      "Found a CountingIdentity layer with counter value 20000 in final state after training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64ddaebbe374db88836537a9e175067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='3.828 MB of 3.828 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MSE_on_fixed_grid</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_within_epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▂▂▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇███████</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>██▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MSE_on_fixed_grid</td><td>0.01741</td></tr><tr><td>batch_within_epoch</td><td>20000</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.13038</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-field-250</strong> at: <a href='https://wandb.ai/nld/inr_edu_24/runs/oija9uck' target=\"_blank\">https://wandb.ai/nld/inr_edu_24/runs/oija9uck</a><br/> View project at: <a href='https://wandb.ai/nld/inr_edu_24' target=\"_blank\">https://wandb.ai/nld/inr_edu_24</a><br/>Synced 5 W&B file(s), 0 media file(s), 4 artifact file(s) and 50 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250130_192909-oija9uck/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and we run the experiment while logging things to wandb\n",
    "with wandb.init(\n",
    "    project='inr_edu_24',\n",
    "    notes='test',\n",
    "    tags=['test']\n",
    ") as run:\n",
    "    results = experiment.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedINR(\n",
       "  terms=(\n",
       "    MLPINR(\n",
       "      layers=(\n",
       "        CountingIdentity(\n",
       "          _embedding_matrix=f32[3],\n",
       "          state_index=StateIndex(marker=0, init=_Sentinel())\n",
       "        ),\n",
       "        SirenLayer(\n",
       "          weights=f32[256,2],\n",
       "          biases=f32[256],\n",
       "          activation_kwargs={'w0': 12.0}\n",
       "        ),\n",
       "        SirenLayer(\n",
       "          weights=f32[256,256],\n",
       "          biases=f32[256],\n",
       "          activation_kwargs={'w0': 12.0}\n",
       "        ),\n",
       "        SirenLayer(\n",
       "          weights=f32[256,256],\n",
       "          biases=f32[256],\n",
       "          activation_kwargs={'w0': 12.0}\n",
       "        ),\n",
       "        Linear(weights=f32[3,256], biases=f32[3], activation_kwargs={})\n",
       "      )\n",
       "    ),\n",
       "  ),\n",
       "  post_processor=<function real_part>\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inr, losses, optimizer_state, state, loss_evaluator, additional_output = results\n",
    "inr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking model and state for CountingIdentity layers\n",
      "Found a CountingIdentity layer with counter value 20000 in final state after training.\n"
     ]
    }
   ],
   "source": [
    "from state_test_objects import after_training_callback, CountingIdentity\n",
    "after_training_callback(losses, inr, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountingIdentity(\n",
       "  _embedding_matrix=f32[3],\n",
       "  state_index=StateIndex(marker=0, init=_Sentinel())\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inr.terms[0].layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(inr.terms[0].layers[0], CountingIdentity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_temp_module.CountingIdentity"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inr.terms[0].layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (inr_edu_24)",
   "language": "python",
   "name": "inr_edu_24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
