{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:05:31.600585816Z",
     "start_time": "2024-11-21T14:05:30.118024968Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 15:05:31.529589: W external/xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.3 which is older than the PTX compiler version 12.6.77. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from flax import linen as nn\n",
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import common_jax_utils as cju\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import ml_collections\n",
    "key = jax.random.PRNGKey(12398)\n",
    "key_gen = cju.key_generator(key)\n",
    "\n",
    "# print(Path.cwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def set_config():\n",
    "    config = ml_collections.ConfigDict()\n",
    "    config.lr = 0.001\n",
    "    config.num_epochs = 3\n",
    "    config.batch_size = 1024\n",
    "\n",
    "\n",
    "    config.in_features = 2\n",
    "    config.out_features = 3\n",
    "    \n",
    "    config.num_layers = 4\n",
    "    config.hidden_features = 256\n",
    "    \n",
    "    \n",
    "    config.s0 = 12\n",
    "    config.w0 = 10\n",
    "    return config\n",
    "\n",
    "\n",
    "config = set_config()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:05:31.600690735Z",
     "start_time": "2024-11-21T14:05:31.591773940Z"
    }
   },
   "id": "2b539433e6573dc5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def parrot():\n",
    "    parent = Path.cwd().parent\n",
    "    parrot = parent / 'example_data' / 'parrot.png'\n",
    "    parrot = plt.imread(parrot)\n",
    "    parrot = jnp.array(parrot)\n",
    "    return parrot\n",
    "\n",
    "\n",
    "def kirby():\n",
    "    parent = Path.cwd().parent\n",
    "    kirby = parent / 'example_data' / 'kirby.png'\n",
    "    kirby = plt.imread(kirby)\n",
    "    kirby = jnp.array(kirby)\n",
    "    return kirby\n",
    "\n",
    "def data_format():\n",
    "    y = parrot()\n",
    "    # y = kirby()\n",
    "    dims = y.shape\n",
    "    x = jnp.array(np.meshgrid(np.arange(y.shape[0]), np.arange(y.shape[1]), indexing='ij')).T.reshape(-1, 2)\n",
    "    y = y.reshape(-1, 3)\n",
    "    return x, y, dims\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def data_loader(batch_size, key):\n",
    "    x, y, _= data_format()\n",
    "    key, subkey = jax.random.split(key)\n",
    "    shuffled = jax.random.permutation(subkey, jnp.arange(x.shape[0]))\n",
    "    x = x[shuffled]\n",
    "    y = y[shuffled]\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        yield x[i:i+batch_size].astype(jnp.complex64), y[i:i+batch_size].astype(jnp.complex64)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:05:31.622947556Z",
     "start_time": "2024-11-21T14:05:31.597143163Z"
    }
   },
   "id": "bd9945ef718d0ac6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def complex_kernel_initialization(rng, shape, dtype):\n",
    "    key, subkey = jax.random.split(rng)\n",
    "    real = jax.random.normal(key, shape, dtype=dtype)\n",
    "    key, subkey = jax.random.split(key)\n",
    "    imag = jax.random.normal(key, shape, dtype=dtype)\n",
    "    return (real + imag.astype(jnp.complex64))/jnp.sqrt(shape[0])\n",
    "\n",
    "def complex_input_kernel_initialization(rng, shape, dtype):\n",
    "    key, w_key = jax.random.split(rng)\n",
    "    in_size = shape[0]\n",
    "    lim = 1./in_size# from https://github.com/vsitzmann/siren/blob/4df34baee3f0f9c8f351630992c1fe1f69114b5f/modules.py#L630\n",
    "\n",
    "    \n",
    "    real = jax.random.uniform(\n",
    "        key=w_key,\n",
    "        shape=shape,\n",
    "        minval=-lim, \n",
    "        maxval=lim,\n",
    "        dtype=dtype\n",
    "        )\n",
    "    key, w_key = jax.random.split(w_key)\n",
    "    imag = jax.random.uniform(\n",
    "        key=w_key,\n",
    "        shape=shape,\n",
    "        minval=-lim, \n",
    "        maxval=lim,\n",
    "        dtype=dtype\n",
    "        )\n",
    "    \n",
    "    return real + 1j*imag\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:05:31.656566208Z",
     "start_time": "2024-11-21T14:05:31.618782183Z"
    }
   },
   "id": "443d145d2010a287"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "def complex_kernel_initialization2(rng, shape, dtype):\n",
    "    key, w_key = jax.random.split(rng)\n",
    "    in_size = shape[0]\n",
    "    lim = jnp.sqrt(6./in_size)/config.w0  # from https://arxiv.org/pdf/2006.09661.pdf subsection.3.2 and appendix 1.5 and https://github.com/vsitzmann/siren/blob/4df34baee3f0f9c8f351630992c1fe1f69114b5f/modules.py#L627\n",
    "    \n",
    "    real = jax.random.uniform(\n",
    "        key=w_key,\n",
    "        shape=shape,\n",
    "        minval=-lim, \n",
    "        maxval=lim,\n",
    "        dtype=dtype\n",
    "        )\n",
    "    key, w_key = jax.random.split(w_key)\n",
    "    imag = jax.random.uniform(\n",
    "        key=w_key,\n",
    "        shape=shape,\n",
    "        minval=-lim, \n",
    "        maxval=lim,\n",
    "        dtype=dtype\n",
    "        )\n",
    "    \n",
    "    return real +  1j*imag\n",
    "    \n",
    "            \n",
    "\n",
    "def complex_wire(x: jax.Array, s0:Union[float, jax.Array], w0:Union[float, jax.Array]):\n",
    "    \"\"\"\n",
    "    Implements a complex version of WIRE\n",
    "    that is exp(j*w0*x)*exp(-|s0*x'|^2)\n",
    "    from https://arxiv.org/pdf/2301.05187\n",
    "\n",
    "    :parameter x: a bunch of `jax.Array`s to be fed to this activation function\n",
    "        var positional\n",
    "    :parameter s0: inverse scale used in the radial part of the wavelet (s_0 in the paper)\n",
    "        keyword only\n",
    "    :parameter w0: w0 parameter used in the rotational art of the wavelet (\\omega_0 in the paper)\n",
    "        keyword only\n",
    "    :return: a `jax.Array` with a shape determined by broadcasting all elements of x to tha same shape\n",
    "    \"\"\"\n",
    "    radial_part = jnp.exp(\n",
    "        -jnp.square(\n",
    "            jnp.abs(\n",
    "                s0 * x\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    rotational_part = 1j*jnp.exp(w0 * x)\n",
    "\n",
    "    return rotational_part*radial_part\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:05:31.681378950Z",
     "start_time": "2024-11-21T14:05:31.635909810Z"
    }
   },
   "id": "25f88334869eb0b8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "class ComplexDense(nn.Module):\n",
    "    in_features: int = 2\n",
    "    hidden_features: int = 256\n",
    "    out_features: int = 3\n",
    "    num_layers: int = 5\n",
    "    s0: float = 12\n",
    "    w0: float = 10\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(\n",
    "            features=self.hidden_features,\n",
    "            kernel_init=complex_input_kernel_initialization,\n",
    "            bias_init=complex_input_kernel_initialization,\n",
    "            name='input_layer'\n",
    "        )(x)\n",
    "        x = complex_wire(x, self.s0, self.w0)\n",
    "        for i in range(self.num_layers):\n",
    "            x = nn.Dense(\n",
    "                features=self.hidden_features,\n",
    "                kernel_init=complex_kernel_initialization2,\n",
    "                bias_init=complex_kernel_initialization2,\n",
    "                name=f'fc{i+1}'\n",
    "            )(x)\n",
    "            x = complex_wire(x, self.s0, self.w0)\n",
    "        \n",
    "        x = nn.Dense(\n",
    "            features=self.out_features,\n",
    "            kernel_init=complex_kernel_initialization2,\n",
    "            bias_init=complex_kernel_initialization2,\n",
    "            name='output_layer'\n",
    "        )(x)\n",
    "        # x = real_wire(x, s0=self.s0, w0=self.w0)\n",
    "        # x = complex_wire(x, s0=self.s0, w0=self.w0)\n",
    "        x = nn.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:05:31.682676087Z",
     "start_time": "2024-11-21T14:05:31.648112680Z"
    }
   },
   "id": "417bf3550f7cedf4"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "def mse_loss(pred, true):\n",
    "    return jnp.mean(jnp.square(pred - true))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def update(model, params, x, y, opt, opt_state):\n",
    "    \"\"\"\n",
    "    Compute the gradient for a batch and update the parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def loss_fn(params, x, true_val, eps=1e-6):\n",
    "        \"\"\"Mean squared error loss.\"\"\"\n",
    "        pred_val = model.apply(params, x)\n",
    "        mse = mse_loss(pred_val, true_val)\n",
    "        mean_true_val = true_val.mean(axis=0, keepdims=True)\n",
    "        scaling = mse_loss(mean_true_val, true_val)\n",
    "        return mse/(scaling + eps)\n",
    "        # return mse\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn, holomorphic=True)(params, x, y)   \n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state, loss\n",
    "\n",
    "def update_complex(model, params, x, y, opt, opt_state):\n",
    "    \n",
    "    def loss_fn(params, x, true_val, eps=1e-6):\n",
    "        \"\"\"Mean squared error loss.\"\"\"\n",
    "        pred_val = model.apply(params, x)\n",
    "        mse = mse_loss(pred_val, true_val)\n",
    "        mean_true_val = true_val.mean(axis=0, keepdims=True)\n",
    "        scaling = mse_loss(mean_true_val, true_val)\n",
    "        return mse/(scaling + eps)\n",
    "        # return mse\n",
    "\n",
    "    loss, vjp_fn = jax.vjp(loss_fn, params, x, y)\n",
    "    grads = vjp_fn(jnp.ones_like(loss))[0]\n",
    "    print(grads[\"params\"])\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_params = optax.apply_updates(params, updates)\n",
    "    return new_params, opt_state, loss\n",
    "    \n",
    "    \n",
    "\n",
    "def render_and_save_image(model, params, epoch, batch_size=1024):\n",
    "    if not Path.exists(Path.cwd() / 'results'):\n",
    "        Path.mkdir(Path.cwd() / 'results')\n",
    "    path = Path.cwd() / 'results'/ f'epoch_{epoch}.png'\n",
    "    pred_ys, _ = test(\n",
    "        model,\n",
    "        params,\n",
    "        batch_size\n",
    "    )\n",
    "    sh = data_format()[2]\n",
    "    pred_ys = pred_ys.reshape(sh)\n",
    "    pred_ys = jnp.real(pred_ys)\n",
    "    plt.imsave(path, pred_ys)\n",
    "    \n",
    "\n",
    "def train(model, params, opt, opt_state, num_epochs, batch_size, key):\n",
    "    \"\"\"\n",
    "    Train the model for a number of epochs.\n",
    "    \"\"\"\n",
    "    x, _, _ = data_format()\n",
    "    size = x.shape[0]//batch_size\n",
    "    \n",
    "    print(f'{size=} steps per epoch')\n",
    "    for epoch in (range(num_epochs)):\n",
    "        \n",
    "        key, subkey = jax.random.split(key)\n",
    "        dl = data_loader(batch_size, key)\n",
    "        \n",
    "        for i, pair in enumerate(dl):\n",
    "            x, y = pair\n",
    "            params, opt_state, loss = update(model, params, x, y, opt, opt_state)\n",
    "            \n",
    "            if jnp.isnan(loss):\n",
    "                raise ValueError('Loss is NaN')\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch: {epoch}, Step: {epoch*size +i }, Loss: {jnp.abs(loss)}')\n",
    "            wandb.log({'loss': jnp.abs(loss), 'step': epoch*size + i})\n",
    "\n",
    "        \n",
    "        render_and_save_image(model, params, epoch, batch_size)\n",
    "        # if epoch % 10 == 0:\n",
    "        #     print(f'Epoch: {epoch}, Loss: {jnp.abs(loss)}')\n",
    "        # wandb.log({'loss': jnp.abs(loss), 'epoch': epoch})\n",
    "        \n",
    "    return params\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(model, params, batch_size):\n",
    "    \n",
    "    def loss_fn(params, x, true_val, eps=1e-6):\n",
    "        \"\"\"Mean squared error loss.\"\"\"\n",
    "        pred_val = model.apply(params, x)\n",
    "        mse = mse_loss(pred_val, true_val)\n",
    "        mean_true_val = true_val.mean(axis=0, keepdims=True)\n",
    "        scaling = mse_loss(mean_true_val, true_val)\n",
    "        return mse/(scaling + eps)\n",
    "        # return mse\n",
    "\n",
    "    \n",
    "    x, y, _ = data_format()\n",
    "    ys = jnp.array([])\n",
    "    for i in range(0, len(x), batch_size):\n",
    "        pred_ys = model.apply(params, x[i:i+batch_size])\n",
    "        if ys.shape[0] == 0:\n",
    "            ys = pred_ys\n",
    "        else:\n",
    "            ys = jnp.vstack((ys, pred_ys))    \n",
    "    # pred_ys = model.apply(params, x)\n",
    "    loss = loss_fn( params, x, y)\n",
    "    return pred_ys, loss\n",
    "    \n",
    "        \n",
    "\n",
    "def main():\n",
    "    wandb.init(project='flax_wire')\n",
    "    \n",
    "    config = set_config()\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    lr = config.lr\n",
    "    num_epochs = config.num_epochs\n",
    "    batch_size = config.batch_size\n",
    "    \n",
    "    \n",
    "    wandb.config.update(config)\n",
    "    \n",
    "    model = ComplexDense(\n",
    "        in_features=config.in_features,\n",
    "        hidden_features=config.hidden_features,\n",
    "        out_features=config.out_features,\n",
    "        num_layers=config.num_layers,\n",
    "        s0=config.s0,\n",
    "        w0=config.w0\n",
    "    )\n",
    "\n",
    "    \n",
    "    params = model.init(next(key_gen), jnp.ones((1, 2)).astype(jnp.complex64))\n",
    "    \n",
    "    print(model)\n",
    "    print(nn.tabulate(model, next(key_gen))(jnp.ones((1, 2)).astype(jnp.complex64)))\n",
    "\n",
    "    \n",
    "    # print the model summary\n",
    "    \n",
    "    \n",
    "    \n",
    "    opt = optax.adam(lr)\n",
    "    \n",
    "    opt_state = opt.init(params)\n",
    "    \n",
    "    trained_params = train(\n",
    "        model=model,\n",
    "        params=params,\n",
    "        opt=opt,\n",
    "        opt_state=opt_state,\n",
    "        num_epochs=num_epochs,\n",
    "        batch_size=batch_size,\n",
    "        key=key\n",
    "    )\n",
    "\n",
    "        \n",
    "    pred_ys, test_loss = test(\n",
    "        model=model,\n",
    "        params=trained_params,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    print(f'Training Done, Test Loss: {jnp.abs(test_loss)}')\n",
    "    wandb.log({'test_loss': jnp.abs(test_loss)})\n",
    "    pred_ys = pred_ys.reshape(data_format()[2])\n",
    "    pred_ys = jnp.real(pred_ys)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    _, y, dims = data_format()\n",
    "    valid_y = y.reshape(dims)\n",
    "    ax[0].imshow(pred_ys)\n",
    "    ax[1].imshow(valid_y)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return pred_ys"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:05:31.743353015Z",
     "start_time": "2024-11-21T14:05:31.663495536Z"
    }
   },
   "id": "e63ac0926ec510c8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmaxwell_litsios\u001B[0m (\u001B[33mbep-circle\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.18.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/home/ovindar/PycharmProjects/INR_BEP/flax_exp/wandb/run-20241121_150532-q88f1ri8</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/bep-circle/flax_wire/runs/q88f1ri8' target=\"_blank\">zesty-music-121</a></strong> to <a href='https://wandb.ai/bep-circle/flax_wire' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/bep-circle/flax_wire' target=\"_blank\">https://wandb.ai/bep-circle/flax_wire</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/bep-circle/flax_wire/runs/q88f1ri8' target=\"_blank\">https://wandb.ai/bep-circle/flax_wire/runs/q88f1ri8</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplexDense(\n",
      "    # attributes\n",
      "    in_features = 2\n",
      "    hidden_features = 256\n",
      "    out_features = 3\n",
      "    num_layers = 4\n",
      "    s0 = 12\n",
      "    w0 = 10\n",
      ")\n",
      "\n",
      "\u001B[3m                              ComplexDense Summary                              \u001B[0m\n",
      "┏━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
      "┃\u001B[1m \u001B[0m\u001B[1mpath        \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mmodule      \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1minputs       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1moutputs       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mparams       \u001B[0m\u001B[1m \u001B[0m┃\n",
      "┡━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
      "│              │ ComplexDense │ \u001B[2mcomplex64\u001B[0m[1,… │ \u001B[2mcomplex64\u001B[0m[1,3] │               │\n",
      "├──────────────┼──────────────┼───────────────┼────────────────┼───────────────┤\n",
      "│ input_layer  │ Dense        │ \u001B[2mcomplex64\u001B[0m[1,… │ \u001B[2mcomplex64\u001B[0m[1,2… │ bias:         │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │ kernel:       │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[2,… │\n",
      "│              │              │               │                │               │\n",
      "│              │              │               │                │ \u001B[1m768 \u001B[0m\u001B[1;2m(6.1 KB)\u001B[0m  │\n",
      "├──────────────┼──────────────┼───────────────┼────────────────┼───────────────┤\n",
      "│ fc1          │ Dense        │ \u001B[2mcomplex64\u001B[0m[1,… │ \u001B[2mcomplex64\u001B[0m[1,2… │ bias:         │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │ kernel:       │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │               │\n",
      "│              │              │               │                │ \u001B[1m65,792 \u001B[0m\u001B[1;2m(526.3\u001B[0m │\n",
      "│              │              │               │                │ \u001B[1;2mKB)\u001B[0m           │\n",
      "├──────────────┼──────────────┼───────────────┼────────────────┼───────────────┤\n",
      "│ fc2          │ Dense        │ \u001B[2mcomplex64\u001B[0m[1,… │ \u001B[2mcomplex64\u001B[0m[1,2… │ bias:         │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │ kernel:       │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │               │\n",
      "│              │              │               │                │ \u001B[1m65,792 \u001B[0m\u001B[1;2m(526.3\u001B[0m │\n",
      "│              │              │               │                │ \u001B[1;2mKB)\u001B[0m           │\n",
      "├──────────────┼──────────────┼───────────────┼────────────────┼───────────────┤\n",
      "│ fc3          │ Dense        │ \u001B[2mcomplex64\u001B[0m[1,… │ \u001B[2mcomplex64\u001B[0m[1,2… │ bias:         │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │ kernel:       │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │               │\n",
      "│              │              │               │                │ \u001B[1m65,792 \u001B[0m\u001B[1;2m(526.3\u001B[0m │\n",
      "│              │              │               │                │ \u001B[1;2mKB)\u001B[0m           │\n",
      "├──────────────┼──────────────┼───────────────┼────────────────┼───────────────┤\n",
      "│ fc4          │ Dense        │ \u001B[2mcomplex64\u001B[0m[1,… │ \u001B[2mcomplex64\u001B[0m[1,2… │ bias:         │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │ kernel:       │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │               │\n",
      "│              │              │               │                │ \u001B[1m65,792 \u001B[0m\u001B[1;2m(526.3\u001B[0m │\n",
      "│              │              │               │                │ \u001B[1;2mKB)\u001B[0m           │\n",
      "├──────────────┼──────────────┼───────────────┼────────────────┼───────────────┤\n",
      "│ output_layer │ Dense        │ \u001B[2mcomplex64\u001B[0m[1,… │ \u001B[2mcomplex64\u001B[0m[1,3] │ bias:         │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[3]  │\n",
      "│              │              │               │                │ kernel:       │\n",
      "│              │              │               │                │ \u001B[2mcomplex64\u001B[0m[25… │\n",
      "│              │              │               │                │               │\n",
      "│              │              │               │                │ \u001B[1m771 \u001B[0m\u001B[1;2m(6.2 KB)\u001B[0m  │\n",
      "├──────────────┼──────────────┼───────────────┼────────────────┼───────────────┤\n",
      "│\u001B[1m \u001B[0m\u001B[1m            \u001B[0m\u001B[1m \u001B[0m│\u001B[1m \u001B[0m\u001B[1m            \u001B[0m\u001B[1m \u001B[0m│\u001B[1m \u001B[0m\u001B[1m             \u001B[0m\u001B[1m \u001B[0m│\u001B[1m \u001B[0m\u001B[1m         Total\u001B[0m\u001B[1m \u001B[0m│\u001B[1m \u001B[0m\u001B[1m264,707 \u001B[0m\u001B[1;2m(2.1 \u001B[0m\u001B[1m \u001B[0m│\n",
      "│\u001B[1m              \u001B[0m│\u001B[1m              \u001B[0m│\u001B[1m               \u001B[0m│\u001B[1m                \u001B[0m│\u001B[1m \u001B[0m\u001B[1;2mMB)\u001B[0m\u001B[1m          \u001B[0m\u001B[1m \u001B[0m│\n",
      "└──────────────┴──────────────┴───────────────┴────────────────┴───────────────┘\n",
      "\u001B[1m                                                                                \u001B[0m\n",
      "\u001B[1m                       Total Parameters: 264,707 \u001B[0m\u001B[1;2m(2.1 MB)\u001B[0m\u001B[1m                       \u001B[0m\n",
      "\n",
      "size=2701 steps per epoch\n",
      "Epoch: 0, Step: 0, Loss: 4.297972202301025\n",
      "Epoch: 0, Step: 100, Loss: 4.167781829833984\n",
      "Epoch: 0, Step: 200, Loss: 4.021570205688477\n",
      "Epoch: 0, Step: 300, Loss: 3.977515697479248\n",
      "Epoch: 0, Step: 400, Loss: 4.1052327156066895\n",
      "Epoch: 0, Step: 500, Loss: 4.090723514556885\n",
      "Epoch: 0, Step: 600, Loss: 4.070533275604248\n",
      "Epoch: 0, Step: 700, Loss: 3.9602534770965576\n",
      "Epoch: 0, Step: 800, Loss: 3.9448657035827637\n",
      "Epoch: 0, Step: 900, Loss: 3.821152925491333\n",
      "Epoch: 0, Step: 1000, Loss: 4.258418560028076\n",
      "Epoch: 0, Step: 1100, Loss: 3.9442243576049805\n",
      "Epoch: 0, Step: 1200, Loss: 4.055558204650879\n",
      "Epoch: 0, Step: 1300, Loss: 3.8263356685638428\n",
      "Epoch: 0, Step: 1400, Loss: 3.832750082015991\n",
      "Epoch: 0, Step: 1500, Loss: 4.03550386428833\n",
      "Epoch: 0, Step: 1600, Loss: 4.031071186065674\n",
      "Epoch: 0, Step: 1700, Loss: 4.274442672729492\n",
      "Epoch: 0, Step: 1800, Loss: 3.908651113510132\n",
      "Epoch: 0, Step: 1900, Loss: 3.8708019256591797\n",
      "Epoch: 0, Step: 2000, Loss: 3.9363574981689453\n",
      "Epoch: 0, Step: 2100, Loss: 4.166440010070801\n",
      "Epoch: 0, Step: 2200, Loss: 3.876279354095459\n",
      "Epoch: 0, Step: 2300, Loss: 4.1059041023254395\n",
      "Epoch: 0, Step: 2400, Loss: 3.8897523880004883\n",
      "Epoch: 0, Step: 2500, Loss: 3.8560380935668945\n",
      "Epoch: 0, Step: 2600, Loss: 4.0008544921875\n",
      "Epoch: 0, Step: 2700, Loss: 3.9136579036712646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 15:11:41.836657: W external/xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 5.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 5682036736 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mXlaRuntimeError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m pys \u001B[38;5;241m=\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 152\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m    148\u001B[0m opt \u001B[38;5;241m=\u001B[39m optax\u001B[38;5;241m.\u001B[39madam(lr)\n\u001B[1;32m    150\u001B[0m opt_state \u001B[38;5;241m=\u001B[39m opt\u001B[38;5;241m.\u001B[39minit(params)\n\u001B[0;32m--> 152\u001B[0m trained_params \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m    \u001B[49m\u001B[43mopt_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mopt_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m pred_ys, test_loss \u001B[38;5;241m=\u001B[39m test(\n\u001B[1;32m    164\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[1;32m    165\u001B[0m     params\u001B[38;5;241m=\u001B[39mtrained_params,\n\u001B[1;32m    166\u001B[0m )\n\u001B[1;32m    167\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining Done, Test Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjnp\u001B[38;5;241m.\u001B[39mabs(test_loss)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[7], line 85\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, params, opt, opt_state, num_epochs, batch_size, key)\u001B[0m\n\u001B[1;32m     81\u001B[0m             \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEpoch: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Step: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;241m*\u001B[39msize\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39mi\u001B[38;5;250m \u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjnp\u001B[38;5;241m.\u001B[39mabs(loss)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     82\u001B[0m         wandb\u001B[38;5;241m.\u001B[39mlog({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m: jnp\u001B[38;5;241m.\u001B[39mabs(loss), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m'\u001B[39m: epoch\u001B[38;5;241m*\u001B[39msize \u001B[38;5;241m+\u001B[39m i})\n\u001B[0;32m---> 85\u001B[0m     \u001B[43mrender_and_save_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;66;03m# if epoch % 10 == 0:\u001B[39;00m\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;66;03m#     print(f'Epoch: {epoch}, Loss: {jnp.abs(loss)}')\u001B[39;00m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;66;03m# wandb.log({'loss': jnp.abs(loss), 'epoch': epoch})\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m params\n",
      "Cell \u001B[0;32mIn[7], line 53\u001B[0m, in \u001B[0;36mrender_and_save_image\u001B[0;34m(model, params, epoch)\u001B[0m\n\u001B[1;32m     51\u001B[0m     Path\u001B[38;5;241m.\u001B[39mmkdir(Path\u001B[38;5;241m.\u001B[39mcwd() \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     52\u001B[0m path \u001B[38;5;241m=\u001B[39m Path\u001B[38;5;241m.\u001B[39mcwd() \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mresults\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m---> 53\u001B[0m pred_ys, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m sh \u001B[38;5;241m=\u001B[39m data_format()[\u001B[38;5;241m2\u001B[39m]\n\u001B[1;32m     55\u001B[0m pred_ys \u001B[38;5;241m=\u001B[39m pred_ys\u001B[38;5;241m.\u001B[39mreshape(sh)\n",
      "Cell \u001B[0;32mIn[7], line 110\u001B[0m, in \u001B[0;36mtest\u001B[0;34m(model, params)\u001B[0m\n\u001B[1;32m    104\u001B[0m     \u001B[38;5;66;03m# return mse\u001B[39;00m\n\u001B[1;32m    107\u001B[0m x, y, _ \u001B[38;5;241m=\u001B[39m data_format()\n\u001B[0;32m--> 110\u001B[0m pred_ys \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn( params, x, y)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m pred_ys, loss\n",
      "    \u001B[0;31m[... skipping hidden 6 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[6], line 11\u001B[0m, in \u001B[0;36mComplexDense.__call__\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;129m@nn\u001B[39m\u001B[38;5;241m.\u001B[39mcompact\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m---> 11\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDense\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhidden_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkernel_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomplex_input_kernel_initialization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbias_init\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomplex_input_kernel_initialization\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minput_layer\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     17\u001B[0m     x \u001B[38;5;241m=\u001B[39m complex_wire(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms0, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mw0)\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers):\n",
      "    \u001B[0;31m[... skipping hidden 2 frame]\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/flax/linen/linear.py:271\u001B[0m, in \u001B[0;36mDense.__call__\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    270\u001B[0m   dot_general \u001B[38;5;241m=\u001B[39m lax\u001B[38;5;241m.\u001B[39mdot_general\n\u001B[0;32m--> 271\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[43mdot_general\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    272\u001B[0m \u001B[43m  \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    273\u001B[0m \u001B[43m  \u001B[49m\u001B[43mkernel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    274\u001B[0m \u001B[43m  \u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndim\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m  \u001B[49m\u001B[43mprecision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    278\u001B[0m   y \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mreshape(bias, (\u001B[38;5;241m1\u001B[39m,) \u001B[38;5;241m*\u001B[39m (y\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m+\u001B[39m (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,))\n",
      "    \u001B[0;31m[... skipping hidden 21 frame]\u001B[0m\n",
      "File \u001B[0;32m~/PycharmProjects/INR_BEP/.venv/lib/python3.10/site-packages/jax/_src/compiler.py:267\u001B[0m, in \u001B[0;36mbackend_compile\u001B[0;34m(backend, module, options, host_callbacks)\u001B[0m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m backend\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m    262\u001B[0m         built_c, compile_options\u001B[38;5;241m=\u001B[39moptions, host_callbacks\u001B[38;5;241m=\u001B[39mhost_callbacks\n\u001B[1;32m    263\u001B[0m     )\n\u001B[1;32m    264\u001B[0m   \u001B[38;5;66;03m# Some backends don't have `host_callbacks` option yet\u001B[39;00m\n\u001B[1;32m    265\u001B[0m   \u001B[38;5;66;03m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001B[39;00m\n\u001B[1;32m    266\u001B[0m   \u001B[38;5;66;03m# to take in `host_callbacks`\u001B[39;00m\n\u001B[0;32m--> 267\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbackend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuilt_c\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcompile_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m xc\u001B[38;5;241m.\u001B[39mXlaRuntimeError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    269\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m error_handler \u001B[38;5;129;01min\u001B[39;00m _XLA_RUNTIME_ERROR_HANDLERS:\n",
      "\u001B[0;31mXlaRuntimeError\u001B[0m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 5682036736 bytes."
     ]
    }
   ],
   "source": [
    "pys = main()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T14:11:43.964537466Z",
     "start_time": "2024-11-21T14:05:31.744728264Z"
    }
   },
   "id": "64ba911958e1f0fe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-21T14:11:43.897414828Z"
    }
   },
   "id": "ec50a06141e90623"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-21T14:11:43.898673438Z"
    }
   },
   "id": "33350a415727b22f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-21T14:11:43.899907211Z"
    }
   },
   "id": "37ec9af8d516f52c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-21T14:11:43.901116584Z"
    }
   },
   "id": "4f0eaa04049b2879"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
